{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "7040e03e-628a-4069-8b86-6c9da4a39462",
    "_uuid": "3da3b93b381cec6ec9c8c9f69627e932498f6bf1"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import (LSTM, \n",
    "                          Embedding, \n",
    "                          BatchNormalization,\n",
    "                          Dense, \n",
    "                          TimeDistributed, \n",
    "                          Dropout, \n",
    "                          Bidirectional,\n",
    "                          Flatten, \n",
    "                          GlobalMaxPool1D)\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import Constant\n",
    "from tensorflow.keras import layers\n",
    "# from keras.layers import (LSTM, \n",
    "#                           Embedding, \n",
    "#                           BatchNormalization,\n",
    "#                           Dense, \n",
    "#                           TimeDistributed, \n",
    "#                           Dropout, \n",
    "#                           Bidirectional,\n",
    "#                           Flatten, \n",
    "#                           GlobalMaxPool1D)\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    classification_report,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3.1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(history, arr):\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(20, 5))\n",
    "    for idx in range(2):\n",
    "        ax[idx].plot(history.history[arr[idx][0]])\n",
    "        ax[idx].plot(history.history[arr[idx][1]])\n",
    "        ax[idx].legend([arr[idx][0], arr[idx][1]],fontsize=18)\n",
    "        ax[idx].set_xlabel('A ',fontsize=16)\n",
    "        ax[idx].set_ylabel('B',fontsize=16)\n",
    "        ax[idx].set_title(arr[idx][0] + ' X ' + arr[idx][1],fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('../input/nlp-getting-started/train.csv')\n",
    "# test = pd.read_csv('../input/nlp-getting-started/test.csv')\n",
    "# submission = pd.read_csv('../input/nlp-getting-started/sample_submission.csv')\n",
    "\n",
    "dataset = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.text.values\n",
    "test = test.text.values\n",
    "sentiments = dataset.target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(train)\n",
    "vocab_length = len(word_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred_tag, y_test):\n",
    "\n",
    "    print(\"F1-score: \", f1_score(pred_tag, y_test))\n",
    "    print(\"Precision: \", precision_score(pred_tag, y_test))\n",
    "    print(\"Recall: \", recall_score(pred_tag, y_test))\n",
    "    print(\"Acuracy: \", accuracy_score(pred_tag, y_test))\n",
    "    print(\"-\"*50)\n",
    "    print(classification_report(pred_tag, y_test))\n",
    "    \n",
    "def embed(corpus): \n",
    "    return word_tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "longest_train = max(train, key=lambda sentence: len(word_tokenize(sentence)))\n",
    "length_long_sentence = len(word_tokenize(longest_train))\n",
    "padded_sentences = pad_sequences(embed(train), length_long_sentence, padding='post')\n",
    "\n",
    "test_sentences = pad_sequences(\n",
    "    embed(test), \n",
    "    length_long_sentence,\n",
    "    padding='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Twitter Gloves\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "embedding_dim = 200\n",
    "# glove_file = open('../input/glove-global-vectors-for-word-representation/glove.6B.' + str(embedding_dim) + 'd.txt', encoding=\"utf8\")\n",
    "glove_file = open('glove.twitter.27B.' + str(embedding_dim) + 'd.txt', encoding=\"utf8\")\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    if index >= vocab_length:\n",
    "        continue\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLSTM():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=embedding_matrix.shape[0], \n",
    "                        output_dim=embedding_matrix.shape[1], \n",
    "                        weights = [embedding_matrix], \n",
    "                        input_length=length_long_sentence,\n",
    "                        trainable=False))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(16)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLSTM():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=embedding_matrix.shape[0], \n",
    "                        output_dim=embedding_matrix.shape[1], \n",
    "                        weights = [embedding_matrix], \n",
    "                        input_length=length_long_sentence,\n",
    "                        trainable=False))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.2)))\n",
    "    model.add(GlobalMaxPool1D())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "Modelo: 0\n",
      "\n",
      "Train on 3806 samples, validate on 3807 samples\n",
      "Epoch 1/15\n",
      "3806/3806 [==============================] - 22s 6ms/step - loss: 0.7251 - accuracy: 0.6398 - val_loss: 0.6279 - val_accuracy: 0.6454\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62790, saving model to model_0.h5\n",
      "Epoch 2/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.5611 - accuracy: 0.7391 - val_loss: 0.5352 - val_accuracy: 0.7962\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62790 to 0.53515, saving model to model_0.h5\n",
      "Epoch 3/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.5086 - accuracy: 0.7709 - val_loss: 0.5022 - val_accuracy: 0.7801\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.53515 to 0.50220, saving model to model_0.h5\n",
      "Epoch 4/15\n",
      "3806/3806 [==============================] - 20s 5ms/step - loss: 0.4640 - accuracy: 0.7916 - val_loss: 0.4417 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50220 to 0.44168, saving model to model_0.h5\n",
      "Epoch 5/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4470 - accuracy: 0.8058 - val_loss: 0.4182 - val_accuracy: 0.8177\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.44168 to 0.41825, saving model to model_0.h5\n",
      "Epoch 6/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4289 - accuracy: 0.8169 - val_loss: 0.4131 - val_accuracy: 0.8211\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41825 to 0.41310, saving model to model_0.h5\n",
      "Epoch 7/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4145 - accuracy: 0.8274 - val_loss: 0.4383 - val_accuracy: 0.8138\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41310\n",
      "Epoch 8/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3917 - accuracy: 0.8395 - val_loss: 0.4086 - val_accuracy: 0.8251\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.41310 to 0.40857, saving model to model_0.h5\n",
      "Epoch 9/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3790 - accuracy: 0.8418 - val_loss: 0.4452 - val_accuracy: 0.8156\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.40857\n",
      "Epoch 10/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3458 - accuracy: 0.8602 - val_loss: 0.4347 - val_accuracy: 0.8272\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.40857\n",
      "Epoch 11/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3363 - accuracy: 0.8647 - val_loss: 0.4434 - val_accuracy: 0.8224\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.40857\n",
      "Epoch 12/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3321 - accuracy: 0.8634 - val_loss: 0.4593 - val_accuracy: 0.8161\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.40857\n",
      "Epoch 13/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2906 - accuracy: 0.8791 - val_loss: 0.5034 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.40857\n",
      "Epoch 14/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2869 - accuracy: 0.8805 - val_loss: 0.5035 - val_accuracy: 0.8130\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.40857\n",
      "Epoch 15/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2683 - accuracy: 0.8973 - val_loss: 0.5090 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.40857\n",
      "********************\n",
      "Modelo: 1\n",
      "\n",
      "Train on 3806 samples, validate on 3807 samples\n",
      "Epoch 1/15\n",
      "3806/3806 [==============================] - 22s 6ms/step - loss: 0.7008 - accuracy: 0.6534 - val_loss: 0.6291 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62909, saving model to model_1.h5\n",
      "Epoch 2/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.5464 - accuracy: 0.7394 - val_loss: 0.5500 - val_accuracy: 0.7455\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62909 to 0.55004, saving model to model_1.h5\n",
      "Epoch 3/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4893 - accuracy: 0.7790 - val_loss: 0.4524 - val_accuracy: 0.8004\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55004 to 0.45237, saving model to model_1.h5\n",
      "Epoch 4/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4536 - accuracy: 0.8156 - val_loss: 0.4295 - val_accuracy: 0.8075\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.45237 to 0.42952, saving model to model_1.h5\n",
      "Epoch 5/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4228 - accuracy: 0.8195 - val_loss: 0.4425 - val_accuracy: 0.8017\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.42952\n",
      "Epoch 6/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4071 - accuracy: 0.8318 - val_loss: 0.4448 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.42952\n",
      "Epoch 7/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4027 - accuracy: 0.8326 - val_loss: 0.4498 - val_accuracy: 0.7993\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.42952\n",
      "Epoch 8/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3721 - accuracy: 0.8473 - val_loss: 0.4681 - val_accuracy: 0.7922\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.42952\n",
      "Epoch 9/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3543 - accuracy: 0.8594 - val_loss: 0.4978 - val_accuracy: 0.7904\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42952\n",
      "Epoch 10/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3244 - accuracy: 0.8731 - val_loss: 0.4808 - val_accuracy: 0.8138\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42952\n",
      "Epoch 11/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3187 - accuracy: 0.8665 - val_loss: 0.4914 - val_accuracy: 0.8085\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42952\n",
      "Epoch 12/15\n",
      "3806/3806 [==============================] - 20s 5ms/step - loss: 0.2972 - accuracy: 0.8807 - val_loss: 0.5054 - val_accuracy: 0.8038\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.42952\n",
      "Epoch 13/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2787 - accuracy: 0.8946 - val_loss: 0.4956 - val_accuracy: 0.8048\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.42952\n",
      "Epoch 14/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2727 - accuracy: 0.8912 - val_loss: 0.5397 - val_accuracy: 0.8119\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.42952\n",
      "Epoch 15/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2574 - accuracy: 0.8967 - val_loss: 0.5427 - val_accuracy: 0.8022\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.42952\n",
      "********************\n",
      "Modelo: 2\n",
      "\n",
      "Train on 3806 samples, validate on 3807 samples\n",
      "Epoch 1/15\n",
      "3806/3806 [==============================] - 22s 6ms/step - loss: 0.7175 - accuracy: 0.6403 - val_loss: 0.6252 - val_accuracy: 0.7520\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.62521, saving model to model_2.h5\n",
      "Epoch 2/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.5447 - accuracy: 0.7528 - val_loss: 0.5503 - val_accuracy: 0.7904\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.62521 to 0.55025, saving model to model_2.h5\n",
      "Epoch 3/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4869 - accuracy: 0.7861 - val_loss: 0.4678 - val_accuracy: 0.8072\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55025 to 0.46775, saving model to model_2.h5\n",
      "Epoch 4/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4478 - accuracy: 0.8045 - val_loss: 0.4304 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.46775 to 0.43040, saving model to model_2.h5\n",
      "Epoch 5/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4347 - accuracy: 0.8114 - val_loss: 0.4493 - val_accuracy: 0.8077\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.43040\n",
      "Epoch 6/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4073 - accuracy: 0.8311 - val_loss: 0.4359 - val_accuracy: 0.8161\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.43040\n",
      "Epoch 7/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.3934 - accuracy: 0.8363 - val_loss: 0.4302 - val_accuracy: 0.8130\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.43040 to 0.43018, saving model to model_2.h5\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3610 - accuracy: 0.8500 - val_loss: 0.4752 - val_accuracy: 0.8148\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.43018\n",
      "Epoch 9/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3522 - accuracy: 0.8529 - val_loss: 0.4587 - val_accuracy: 0.8135\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.43018\n",
      "Epoch 10/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3477 - accuracy: 0.8605 - val_loss: 0.5145 - val_accuracy: 0.8048\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.43018\n",
      "Epoch 11/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3248 - accuracy: 0.8673 - val_loss: 0.4874 - val_accuracy: 0.8117\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.43018\n",
      "Epoch 12/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2892 - accuracy: 0.8791 - val_loss: 0.5390 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.43018\n",
      "Epoch 13/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2808 - accuracy: 0.8823 - val_loss: 0.5412 - val_accuracy: 0.8038\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.43018\n",
      "Epoch 14/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2788 - accuracy: 0.8857 - val_loss: 0.5781 - val_accuracy: 0.8114\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.43018\n",
      "Epoch 15/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2728 - accuracy: 0.8949 - val_loss: 0.5457 - val_accuracy: 0.8127\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.43018\n",
      "********************\n",
      "Modelo: 3\n",
      "\n",
      "Train on 3806 samples, validate on 3807 samples\n",
      "Epoch 1/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.7135 - accuracy: 0.6379 - val_loss: 0.6443 - val_accuracy: 0.6443\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64425, saving model to model_3.h5\n",
      "Epoch 2/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.5681 - accuracy: 0.7417 - val_loss: 0.5647 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.64425 to 0.56470, saving model to model_3.h5\n",
      "Epoch 3/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4891 - accuracy: 0.7867 - val_loss: 0.4792 - val_accuracy: 0.7941\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.56470 to 0.47917, saving model to model_3.h5\n",
      "Epoch 4/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4691 - accuracy: 0.7977 - val_loss: 0.4598 - val_accuracy: 0.7988\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.47917 to 0.45978, saving model to model_3.h5\n",
      "Epoch 5/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.4341 - accuracy: 0.8166 - val_loss: 0.4315 - val_accuracy: 0.8088\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.45978 to 0.43146, saving model to model_3.h5\n",
      "Epoch 6/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4142 - accuracy: 0.8355 - val_loss: 0.4272 - val_accuracy: 0.8077\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.43146 to 0.42718, saving model to model_3.h5\n",
      "Epoch 7/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3934 - accuracy: 0.8395 - val_loss: 0.4327 - val_accuracy: 0.8125\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.42718\n",
      "Epoch 8/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3714 - accuracy: 0.8518 - val_loss: 0.4348 - val_accuracy: 0.8096\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.42718\n",
      "Epoch 9/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3613 - accuracy: 0.8544 - val_loss: 0.4318 - val_accuracy: 0.8080\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.42718\n",
      "Epoch 10/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3354 - accuracy: 0.8613 - val_loss: 0.4557 - val_accuracy: 0.8069\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.42718\n",
      "Epoch 11/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3310 - accuracy: 0.8728 - val_loss: 0.4579 - val_accuracy: 0.8030\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42718\n",
      "Epoch 12/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.3106 - accuracy: 0.8707 - val_loss: 0.5053 - val_accuracy: 0.7925\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.42718\n",
      "Epoch 13/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2894 - accuracy: 0.8915 - val_loss: 0.4862 - val_accuracy: 0.8054\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.42718\n",
      "Epoch 14/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2806 - accuracy: 0.8849 - val_loss: 0.5378 - val_accuracy: 0.8093\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.42718\n",
      "Epoch 15/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.2644 - accuracy: 0.8999 - val_loss: 0.5623 - val_accuracy: 0.8025\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.42718\n",
      "********************\n",
      "Modelo: 4\n",
      "\n",
      "Train on 3806 samples, validate on 3807 samples\n",
      "Epoch 1/15\n",
      "3806/3806 [==============================] - 22s 6ms/step - loss: 0.6849 - accuracy: 0.6477 - val_loss: 0.6508 - val_accuracy: 0.5632\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.65084, saving model to model_4.h5\n",
      "Epoch 2/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.5520 - accuracy: 0.7454 - val_loss: 0.5568 - val_accuracy: 0.7773\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.65084 to 0.55678, saving model to model_4.h5\n",
      "Epoch 3/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.5082 - accuracy: 0.7746 - val_loss: 0.4787 - val_accuracy: 0.7941\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.55678 to 0.47866, saving model to model_4.h5\n",
      "Epoch 4/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4739 - accuracy: 0.7895 - val_loss: 0.4381 - val_accuracy: 0.8143\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.47866 to 0.43812, saving model to model_4.h5\n",
      "Epoch 5/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4354 - accuracy: 0.8158 - val_loss: 0.4185 - val_accuracy: 0.8182\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.43812 to 0.41849, saving model to model_4.h5\n",
      "Epoch 6/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.4237 - accuracy: 0.8190 - val_loss: 0.4152 - val_accuracy: 0.8222\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.41849 to 0.41522, saving model to model_4.h5\n",
      "Epoch 7/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.3968 - accuracy: 0.8295 - val_loss: 0.4242 - val_accuracy: 0.8193\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.41522\n",
      "Epoch 8/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3871 - accuracy: 0.8387 - val_loss: 0.4334 - val_accuracy: 0.8188\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.41522\n",
      "Epoch 9/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.3624 - accuracy: 0.8550 - val_loss: 0.4341 - val_accuracy: 0.8214\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.41522\n",
      "Epoch 10/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.3583 - accuracy: 0.8481 - val_loss: 0.4287 - val_accuracy: 0.8227\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41522\n",
      "Epoch 11/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3264 - accuracy: 0.8650 - val_loss: 0.4625 - val_accuracy: 0.8203\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.001.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.41522\n",
      "Epoch 12/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3138 - accuracy: 0.8760 - val_loss: 0.4830 - val_accuracy: 0.8151\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.41522\n",
      "Epoch 13/15\n",
      "3806/3806 [==============================] - 21s 5ms/step - loss: 0.3008 - accuracy: 0.8747 - val_loss: 0.5050 - val_accuracy: 0.8130\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.41522\n",
      "Epoch 14/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.2809 - accuracy: 0.8878 - val_loss: 0.5111 - val_accuracy: 0.8148\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.41522\n",
      "Epoch 15/15\n",
      "3806/3806 [==============================] - 21s 6ms/step - loss: 0.2653 - accuracy: 0.8941 - val_loss: 0.5394 - val_accuracy: 0.8119\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.41522\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.2, \n",
    "    verbose =1, \n",
    "    patience=5,                        \n",
    "    min_lr=0.001\n",
    ")\n",
    "\n",
    "for idx in range(5):\n",
    "    \n",
    "    print(\"*\"*20 + '\\nModelo: ' + str(idx) + '\\n')\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss', \n",
    "        factor=0.2, \n",
    "        verbose =1, \n",
    "        patience=5,                        \n",
    "        min_lr=0.001\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        'model_' + str(idx)+ '.h5', \n",
    "        monitor='val_loss',\n",
    "        mode='auto',\n",
    "        verbose=1,\n",
    "        save_weights_only = True,\n",
    "        save_best_only=True\n",
    "    )\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        padded_sentences, \n",
    "        sentiments, \n",
    "        test_size=0.5\n",
    "    )\n",
    "    \n",
    "    model = BLSTM()\n",
    "    model.fit(X_train,\n",
    "              y_train,\n",
    "              batch_size=32,\n",
    "              epochs=15,\n",
    "              validation_data=[X_test, y_test],\n",
    "              callbacks = [reduce_lr, checkpoint],\n",
    "              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 704 ms, total: 20.6 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from glob import glob\n",
    "import scipy\n",
    "\n",
    "x_models = []\n",
    "labels = []\n",
    "\n",
    "# Carregando os Modelos\n",
    "for idx in glob('*.h5'):\n",
    "    model = BLSTM()\n",
    "    model.load_weights(idx)\n",
    "    x_models.append(model)\n",
    "    \n",
    "# Predizendo Classes para o conjunto de Testes\n",
    "for idx in x_models:\n",
    "    preds = idx.predict_classes(test_sentences)\n",
    "    labels.append(preds)\n",
    "\n",
    "#Votando nas classes, baseando na moda estatística \n",
    "labels = scipy.stats.mode(labels)[0]\n",
    "labels = np.squeeze(labels)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission.target = labels\n",
    "print(labels)\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "submission.target.value_counts().plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>10861</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3259</th>\n",
       "      <td>10865</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260</th>\n",
       "      <td>10868</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>10874</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>10875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3263 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  target\n",
       "0         0       1\n",
       "1         2       1\n",
       "2         3       1\n",
       "3         9       1\n",
       "4        11       1\n",
       "...     ...     ...\n",
       "3258  10861       1\n",
       "3259  10865       1\n",
       "3260  10868       1\n",
       "3261  10874       1\n",
       "3262  10875       0\n",
       "\n",
       "[3263 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
